{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquiring Educational Data for Reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:21:46.001812Z",
     "start_time": "2021-02-04T23:21:43.207670Z"
    }
   },
   "outputs": [],
   "source": [
    "# Database connection and authentication\n",
    "import configparser\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "\n",
    "# Scraping\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from mediawiki import MediaWiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database and Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:21:46.033817Z",
     "start_time": "2021-02-04T23:21:46.004376Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read config.ini file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('./auth/config.ini')\n",
    "\n",
    "# Get Google Firebase Auth\n",
    "GCP_AUTH_PATH = config.get('firebase', 'GCP_AUTH_PATH')\n",
    "cred = credentials.Certificate(GCP_AUTH_PATH)\n",
    "app = firebase_admin.initialize_app(cred)\n",
    "\n",
    "# Instantiate connection to database\n",
    "db = firestore.client()\n",
    "\n",
    "# Google Knowledge Graph API Key\n",
    "GCP_API_KEY = config.get('gcpkeys', 'GCP_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:21:46.263584Z",
     "start_time": "2021-02-04T23:21:46.260869Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate collection reference\n",
    "ref = db.collection(\"reps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire Rep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:21:48.202615Z",
     "start_time": "2021-02-04T23:21:47.312578Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve all reps\n",
    "query = ref.where(\"_id\", \"!=\", \"\").select([\"_id\", \"google_id\", \"first_name\", \"middle_name\", \"last_name\"]).stream()\n",
    "reps = [ doc.to_dict() for doc in query ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Missing Google Entity IDs\n",
    "- Certain reps have missing Google Entity IDs\n",
    "- Acquire Google Entity IDs utilizing the Google Knowledge Graph API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:21:49.793990Z",
     "start_time": "2021-02-04T23:21:49.788609Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_google_id(rep):\n",
    "    '''\n",
    "    Function to find Google Entity ID\n",
    "    '''\n",
    "    \n",
    "    first_name = rep[\"first_name\"]\n",
    "    last_name = rep[\"last_name\"]\n",
    "    name = f'{first_name} {last_name} politician'\n",
    "    params = {\n",
    "        'query': name,\n",
    "        'limit': 10,\n",
    "        'indent': True,\n",
    "        'key': GCP_API_KEY,\n",
    "    }\n",
    "\n",
    "    service_url = 'https://kgsearch.googleapis.com/v1/entities:search'\n",
    "    url = service_url + '?'\n",
    "    r = requests.get(url, params=params)\n",
    "    result = r.json()['itemListElement'][0]['result']\n",
    "    _id = result['@id'][3:]\n",
    "    \n",
    "    return _id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:21:52.237312Z",
     "start_time": "2021-02-04T23:21:50.855670Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find and assign Google Entity IDs for reps with missing google_ids\n",
    "for rep in reps:\n",
    "    if rep['google_id'] == None:\n",
    "        rep['google_id'] = find_google_id(rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Wikipedia Page from Google Knowledge Graph API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:21:58.716379Z",
     "start_time": "2021-02-04T23:21:58.710541Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_google_entity(rep):\n",
    "    '''\n",
    "    Function to get Google entity JSON\n",
    "    '''\n",
    "    \n",
    "    google_id = rep['google_id']\n",
    "    params = {\n",
    "        'ids': google_id,\n",
    "        'limit': 10,\n",
    "        'indent': True,\n",
    "        'key': GCP_API_KEY,\n",
    "    }\n",
    "\n",
    "    service_url = 'https://kgsearch.googleapis.com/v1/entities:search'\n",
    "    url = service_url + '?'\n",
    "    r = requests.get(url, params=params)\n",
    "    result = r.json()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:21:59.596879Z",
     "start_time": "2021-02-04T23:21:59.592530Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wiki_url(rep):\n",
    "    '''\n",
    "    Function to get wiki_url if it exists in Google Knowledge Graph,\n",
    "    returns tuple (wiki_url, error)\n",
    "    '''\n",
    "    \n",
    "    result = get_google_entity(rep)\n",
    "    \n",
    "    wiki_url = None\n",
    "    try:\n",
    "        wiki_url = result['itemListElement'][0]['result']['detailedDescription']['url']\n",
    "        return wiki_url, None\n",
    "    except Exception as e:\n",
    "        return wiki_url, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:23:59.866845Z",
     "start_time": "2021-02-04T23:22:00.495101Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get Wikipedia URLs for reps\n",
    "for rep in reps:\n",
    "    rep['wiki_url'], rep['error'] = get_wiki_url(rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:23:59.875878Z",
     "start_time": "2021-02-04T23:23:59.869952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check errors\n",
    "errors = {}\n",
    "for rep in reps:\n",
    "    error = rep['error']\n",
    "    if error == None:\n",
    "        pass\n",
    "    else:\n",
    "        e_type = type(error)\n",
    "        if e_type not in errors.keys():\n",
    "            errors[e_type] = []\n",
    "        \n",
    "        errors[e_type].append(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:23:59.889318Z",
     "start_time": "2021-02-04T23:23:59.882638Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'IndexError'> errors: 16\n",
      "<class 'KeyError'> errors: 14\n"
     ]
    }
   ],
   "source": [
    "# Check number of errors by type\n",
    "for k in errors.keys():\n",
    "    print(k, 'errors:', len(errors[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IndexError: Incorrect Google Entity IDs from ProPublica database\n",
    "- Use Google Knowledge Graph to get new IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:24:03.318352Z",
     "start_time": "2021-02-04T23:23:59.894076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "# Determine if ProPublica google_id is incorrect\n",
    "i = 0\n",
    "for rep in errors[IndexError]:\n",
    "    if find_google_id(rep) != rep['google_id']:\n",
    "        i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:24:10.696669Z",
     "start_time": "2021-02-04T23:24:03.321311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Use new Google Entity ID to get Wikipedia URL\n",
    "i = 0\n",
    "for rep in errors[IndexError]:\n",
    "    rep['google_id'] = find_google_id(rep)\n",
    "    rep['wiki_url'], rep['error'] = get_wiki_url(rep)\n",
    "    if rep['error'] != None:\n",
    "        i += 1\n",
    "print(i) # Number of reps still with error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T22:14:36.755823Z",
     "start_time": "2021-02-04T22:14:36.327334Z"
    }
   },
   "source": [
    "#### KeyError: Google Entity missing Wikipedia page URL\n",
    "- Use MediaWiki package to get page URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:24:10.869153Z",
     "start_time": "2021-02-04T23:24:10.698586Z"
    }
   },
   "outputs": [],
   "source": [
    "wikipedia = MediaWiki()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:24:17.557663Z",
     "start_time": "2021-02-04T23:24:10.871113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Get Wikipedia URLs\n",
    "i = 0\n",
    "for rep in errors[KeyError]:\n",
    "    try:\n",
    "        name = get_google_entity(rep)['itemListElement'][0]['result']['name']\n",
    "        p = wikipedia.page(f'{name} politician')\n",
    "        rep['wiki_url'] = p.url\n",
    "        rep['error'] = None\n",
    "    except:\n",
    "        i += 1\n",
    "print(i) # Number of reps still with error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Educational Background with Wikipedia Scrape\n",
    "- Note: All rep errors are None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:24:17.569305Z",
     "start_time": "2021-02-04T23:24:17.563585Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_education(wiki_url):\n",
    "    '''\n",
    "    Function to get education from wikipedia infobox,\n",
    "    returns tuple (education, error)\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(wiki_url).text\n",
    "        soup = BeautifulSoup(r)\n",
    "        box = soup.find('table', attrs={'class': 'infobox vcard'})\n",
    "        sibling = True\n",
    "        edus = box.find('th', text='Education').next_sibling\n",
    "        edu = [ a.text for a in edus.find_all('a') ]\n",
    "        return edu, None\n",
    "    except Exception as e:\n",
    "        return None, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:27:11.029492Z",
     "start_time": "2021-02-04T23:24:17.571883Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get education from Wikipedia with error saving\n",
    "errors = {}\n",
    "for rep in reps:\n",
    "    wiki_url = rep['wiki_url']\n",
    "    rep['education'], rep['error'] = get_education(wiki_url)\n",
    "    if rep['error'] == None:\n",
    "        pass\n",
    "    else:\n",
    "        e_type = type(rep['error'])\n",
    "        if e_type not in errors.keys():\n",
    "            errors[e_type] = []\n",
    "        \n",
    "        errors[e_type].append(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:27:11.035598Z",
     "start_time": "2021-02-04T23:27:11.032120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'AttributeError'> errors: 13\n"
     ]
    }
   ],
   "source": [
    "# Check number of errors by type\n",
    "for k in errors.keys():\n",
    "    print(k, 'errors:', len(errors[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funny Detour\n",
    "- The Google Entity ID provided by ProPublica for Texas Politician John Carter was the ID for the movie *John Carter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:27:11.181865Z",
     "start_time": "2021-02-04T23:27:11.037846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@context': {'detailedDescription': 'goog:detailedDescription',\n",
       "  '@vocab': 'http://schema.org/',\n",
       "  'EntitySearchResult': 'goog:EntitySearchResult',\n",
       "  'kg': 'http://g.co/kg',\n",
       "  'resultScore': 'goog:resultScore',\n",
       "  'goog': 'http://schema.googleapis.com/'},\n",
       " '@type': 'ItemList',\n",
       " 'itemListElement': [{'result': {'detailedDescription': {'articleBody': 'John Carter is a 2012 American science fiction action film directed by Andrew Stanton, written by Stanton, Mark Andrews, and Michael Chabon, and based on A Princess of Mars, the first book in the Barsoom series of novels by Edgar Rice Burroughs. ',\n",
       "     'license': 'https://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License',\n",
       "     'url': 'https://en.wikipedia.org/wiki/John_Carter_(film)'},\n",
       "    '@id': 'kg:/m/03whyr',\n",
       "    'url': 'http://movies.disney.com/john-carter',\n",
       "    '@type': ['Thing', 'Movie'],\n",
       "    'name': 'John Carter',\n",
       "    'description': '2012 film'},\n",
       "   '@type': 'EntitySearchResult',\n",
       "   'resultScore': 0}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# John Carter from ProPublica provided Google Entity ID\n",
    "get_google_entity(errors[AttributeError][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:32:14.897733Z",
     "start_time": "2021-02-04T23:32:14.631716Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find results for John Carter\n",
    "rep = errors[AttributeError][2]\n",
    "first_name = rep[\"first_name\"]\n",
    "last_name = rep[\"last_name\"]\n",
    "name = f'{first_name} {last_name}'\n",
    "params = {\n",
    "    'query': name,\n",
    "    'limit': 10,\n",
    "    'indent': True,\n",
    "    'key': GCP_API_KEY,\n",
    "}\n",
    "service_url = 'https://kgsearch.googleapis.com/v1/entities:search'\n",
    "url = service_url + '?'\n",
    "r = requests.get(url, params=params)\n",
    "result = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:39:10.253617Z",
     "start_time": "2021-02-04T23:39:10.250347Z"
    }
   },
   "outputs": [],
   "source": [
    "# Narrow to only 'Person' entities\n",
    "possible = []\n",
    "for r in result['itemListElement']:\n",
    "    if 'Person' in r['result']['@type']:\n",
    "        possible.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:40:04.744235Z",
     "start_time": "2021-02-04T23:40:04.738974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@type': 'EntitySearchResult',\n",
       " 'resultScore': 1094.960693359375,\n",
       " 'result': {'@type': ['Thing', 'Person'],\n",
       "  'detailedDescription': {'url': 'https://en.wikipedia.org/wiki/John_Carter_(Texas_politician)',\n",
       "   'license': 'https://en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License',\n",
       "   'articleBody': \"John Rice Carter is the U.S. Representative serving Texas's 31st congressional district since 2003. He is a Republican. The district includes the northern suburbs of Austin, as well as Fort Hood.\"},\n",
       "  'description': 'U.S. Representative',\n",
       "  'url': 'http://carter.house.gov/',\n",
       "  'name': 'John Carter',\n",
       "  '@id': 'kg:/m/04m7rg'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by highest resultScore\n",
    "possible.sort(key=lambda x: x['resultScore'], reverse=True)\n",
    "possible[0] # Correct John Carter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:45:07.461090Z",
     "start_time": "2021-02-04T23:45:07.068193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace John Carter (movie) with John Carter (politician)\n",
    "errors[AttributeError][2]['google_id'] = possible[0]['result']['@id']\n",
    "errors[AttributeError][2]['wiki_url'] = possible[0]['result']['detailedDescription']['url']\n",
    "\n",
    "# Get educational background\n",
    "rep = errors[AttributeError][2]\n",
    "rep['education'], rep['error'] = get_education(wiki_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:50:34.406184Z",
     "start_time": "2021-02-04T23:50:34.401278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'C001051',\n",
       " 'middle_name': None,\n",
       " 'last_name': 'Carter',\n",
       " 'google_id': 'kg:/m/04m7rg',\n",
       " 'first_name': 'John',\n",
       " 'wiki_url': 'https://en.wikipedia.org/wiki/John_Carter_(Texas_politician)',\n",
       " 'error': None,\n",
       " 'education': ['State University of New York, Albany',\n",
       "  'BA',\n",
       "  'Albany Law School',\n",
       "  'JD']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "errors[AttributeError].pop(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-04T23:51:14.734188Z",
     "start_time": "2021-02-04T23:51:14.729510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(errors[AttributeError])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End Detour\n",
    "#### AttributeError: No 'Education' Section in Wikipedia Page Infobox\n",
    "- Some are in 'Personal details' section in 'Alma mater' row\n",
    "- Some have no tertiary education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T00:15:21.266850Z",
     "start_time": "2021-02-05T00:15:21.229322Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reassign errors\n",
    "errors = errors[AttributeError]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T00:37:17.111433Z",
     "start_time": "2021-02-05T00:37:17.105960Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_alma_mater(rep):\n",
    "    '''\n",
    "    Function for alternative education scrape of Wikipedia page\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        url = rep['wiki_url']\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content)\n",
    "        infobox = soup.find('table', attrs={'class': 'infobox vcard'})\n",
    "        am = infobox.find('a', attrs={'title': 'Alma mater'})\n",
    "        edu = [ a.text for a in am.parent.next_sibling.find_all('a') ]\n",
    "        return edu, None\n",
    "    except Exception as e:\n",
    "        return None, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T00:38:31.732291Z",
     "start_time": "2021-02-05T00:38:26.859668Z"
    }
   },
   "outputs": [],
   "source": [
    "# No tertiary education\n",
    "no_edus = []\n",
    "for rep in errors:\n",
    "    rep['education'], rep['error'] = get_alma_mater(rep)\n",
    "    if rep['error'] != None:\n",
    "        no_edus.append(rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Education and Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T00:44:50.275104Z",
     "start_time": "2021-02-05T00:44:50.270975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove error keys from rep dictionaries\n",
    "for rep in reps:\n",
    "    del rep['error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on Function:\n",
    "- Dictionary ```{degree: institution}``` was not used as the possibility of an individual earning 2 of the same degree types will result in key conflicts.  Additionally, ```{institution: degree}``` dictionary was not used as an individual may earn more than 1 degree from the same institution.\n",
    "- Tuples were not used as many databases do not accept tuples as data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T01:18:51.822106Z",
     "start_time": "2021-02-05T01:18:51.814561Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_education(rep):\n",
    "    '''\n",
    "    Function to pair degree with institution and standardize non-degrees\n",
    "    '''\n",
    "    \n",
    "    edu = rep['education']\n",
    "    if edu == None:\n",
    "        return [['HS', 'HS']]\n",
    "    if len(edu) < 2:\n",
    "        return [['HS', 'HS']]\n",
    "    \n",
    "    edu_list = []\n",
    "    for i in range(len(edu)):\n",
    "        institute = None\n",
    "        degree = None\n",
    "        if len(edu[i]) < 5:\n",
    "            degree = edu[i]\n",
    "            for j in range(i-1, -1, -1):\n",
    "                if len(edu[j]) >= 5:\n",
    "                    institute = edu[j]\n",
    "                    edu_list.append([degree, institute])\n",
    "                    break\n",
    "\n",
    "    return edu_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T01:16:05.299175Z",
     "start_time": "2021-02-05T01:16:05.292483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean education\n",
    "for rep in reps:\n",
    "    rep['education'] = clean_education(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T01:20:23.804490Z",
     "start_time": "2021-02-05T01:20:23.799504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_name': 'Jason',\n",
       " 'google_id': '/g/11gzqdw_wg',\n",
       " 'last_name': 'Crow',\n",
       " '_id': 'C001121',\n",
       " 'middle_name': None,\n",
       " 'wiki_url': 'https://en.wikipedia.org/wiki/Jason_Crow',\n",
       " 'education': [['BA', 'University of Wisconsin, Madison'],\n",
       "  ['JD', 'University of Denver']]}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample\n",
    "reps[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Insert Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting Updated Google Entity IDs and Wikipedia URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T02:21:37.172429Z",
     "start_time": "2021-02-05T02:21:36.557804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 reps updated in batch #1\n",
      "201 reps updated in batch #2\n",
      "106 reps updated in batch #3\n",
      "508 reps updated in total\n"
     ]
    }
   ],
   "source": [
    "batch = db.batch()\n",
    "total = 0\n",
    "insert_len = 0\n",
    "batch_num = 1\n",
    "for rep in reps:\n",
    "    insert_ref = db.collection(\"reps\").document(rep['_id'])\n",
    "    up_dict = {\n",
    "        'google_id': rep['google_id'],\n",
    "        'wiki_url': rep['wiki_url'],\n",
    "    }\n",
    "    batch.update(insert_ref, up_dict)\n",
    "    insert_len += 1\n",
    "    total += 1\n",
    "    if insert_len > 200:\n",
    "        batch.commit()\n",
    "        print(f'{insert_len} reps updated in batch #{batch_num}')\n",
    "        insert_len = 0\n",
    "        batch_num += 1\n",
    "        \n",
    "batch.commit()\n",
    "print(f'{insert_len} reps updated in batch #{batch_num}')\n",
    "print(f'{total} reps updated in total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting into New Collection 'edu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T02:34:18.715700Z",
     "start_time": "2021-02-05T02:34:17.395762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 degrees inserted in batch #1\n",
      "400 degrees inserted in batch #2\n",
      "135 degrees inserted in batch #3\n",
      "935 degrees inserted in total\n"
     ]
    }
   ],
   "source": [
    "batch = db.batch()\n",
    "total = 0\n",
    "insert_len = 0\n",
    "batch_num = 1\n",
    "for rep in reps:\n",
    "    for edu in rep['education']:\n",
    "        insert_ref = db.collection(\"edu\").document()\n",
    "        data = {\n",
    "            '_id': rep['_id'],\n",
    "            'degree': edu[0],\n",
    "            'institution': edu[1]\n",
    "        }\n",
    "        batch.set(insert_ref, data)\n",
    "        insert_len += 1\n",
    "        total += 1\n",
    "        if insert_len > 399:\n",
    "            batch.commit()\n",
    "            print(f'{insert_len} degrees inserted in batch #{batch_num}')\n",
    "            insert_len = 0\n",
    "            batch_num += 1\n",
    "\n",
    "batch.commit()\n",
    "print(f'{insert_len} degrees inserted in batch #{batch_num}')\n",
    "print(f'{total} degrees inserted in total')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "db-env",
   "language": "python",
   "name": "db-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
